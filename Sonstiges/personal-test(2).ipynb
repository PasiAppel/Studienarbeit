{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-27T19:25:18.781392Z",
     "iopub.status.busy": "2022-01-27T19:25:18.780765Z",
     "iopub.status.idle": "2022-01-27T19:25:21.214753Z",
     "shell.execute_reply": "2022-01-27T19:25:21.213929Z",
     "shell.execute_reply.started": "2022-01-27T19:25:18.781263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/pasca/Documents/Test/building_metadata.csv\n",
      "E:/pasca/Documents/Test/sample_submission.csv\n",
      "E:/pasca/Documents/Test/test.csv\n",
      "E:/pasca/Documents/Test/train.csv\n",
      "E:/pasca/Documents/Test/weather_test.csv\n",
      "E:/pasca/Documents/Test/weather_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('E:/pasca/Documents/Test/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import os, gc, warnings\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import sklearn\n",
    "import category_encoders\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:25:21.219093Z",
     "iopub.status.busy": "2022-01-27T19:25:21.218814Z",
     "iopub.status.idle": "2022-01-27T19:25:36.903564Z",
     "shell.execute_reply": "2022-01-27T19:25:36.902738Z",
     "shell.execute_reply.started": "2022-01-27T19:25:21.219057Z"
    }
   },
   "outputs": [],
   "source": [
    "#data import\n",
    "path = \"E:/pasca/Documents/Test/\"\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "building_df = pd.read_csv(path + 'building_metadata.csv')\n",
    "weather_df = pd.read_csv(path + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:25:36.905025Z",
     "iopub.status.busy": "2022-01-27T19:25:36.904802Z",
     "iopub.status.idle": "2022-01-27T19:25:37.066127Z",
     "shell.execute_reply": "2022-01-27T19:25:37.065267Z",
     "shell.execute_reply.started": "2022-01-27T19:25:36.905000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/aitude/ashrae-missing-weather-data-handling by @aitude\n",
    "\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def features_engineering(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    df['square_feet'] =  np.log1p(df['square_feet']**0.5)\n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    #drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n",
    "    #df = df.drop(drop, axis=1)\n",
    "    #gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:25:37.067476Z",
     "iopub.status.busy": "2022-01-27T19:25:37.067238Z",
     "iopub.status.idle": "2022-01-27T19:26:00.174519Z",
     "shell.execute_reply": "2022-01-27T19:26:00.173920Z",
     "shell.execute_reply.started": "2022-01-27T19:25:37.067447Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_df = fill_weather_dataset(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:00.176607Z",
     "iopub.status.busy": "2022-01-27T19:26:00.176236Z",
     "iopub.status.idle": "2022-01-27T19:26:02.750558Z",
     "shell.execute_reply": "2022-01-27T19:26:02.749693Z",
     "shell.execute_reply.started": "2022-01-27T19:26:00.176570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 173.84 MB\n",
      "Decreased by 71.8%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.9%\n",
      "Memory usage of dataframe is 10.72 MB\n",
      "Memory usage after optimization is: 2.73 MB\n",
      "Decreased by 74.5%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:02.751888Z",
     "iopub.status.busy": "2022-01-27T19:26:02.751668Z",
     "iopub.status.idle": "2022-01-27T19:26:10.461185Z",
     "shell.execute_reply": "2022-01-27T19:26:10.460279Z",
     "shell.execute_reply.started": "2022-01-27T19:26:02.751860Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:10.463034Z",
     "iopub.status.busy": "2022-01-27T19:26:10.462493Z",
     "iopub.status.idle": "2022-01-27T19:26:25.612213Z",
     "shell.execute_reply": "2022-01-27T19:26:25.611252Z",
     "shell.execute_reply.started": "2022-01-27T19:26:10.462973Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = features_engineering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:25.614344Z",
     "iopub.status.busy": "2022-01-27T19:26:25.614036Z",
     "iopub.status.idle": "2022-01-27T19:26:36.838627Z",
     "shell.execute_reply": "2022-01-27T19:26:36.837793Z",
     "shell.execute_reply.started": "2022-01-27T19:26:25.614298Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(train_df.loc[train_df['building_id']== 1099].index, inplace=True)\n",
    "train_df.drop(train_df.loc[train_df['building_id']== 778].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:36.840236Z",
     "iopub.status.busy": "2022-01-27T19:26:36.839846Z",
     "iopub.status.idle": "2022-01-27T19:26:36.845825Z",
     "shell.execute_reply": "2022-01-27T19:26:36.845061Z",
     "shell.execute_reply.started": "2022-01-27T19:26:36.840202Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_df[\"year_built\"]\n",
    "del train_df[\"floor_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:36.847769Z",
     "iopub.status.busy": "2022-01-27T19:26:36.847298Z",
     "iopub.status.idle": "2022-01-27T19:26:39.925880Z",
     "shell.execute_reply": "2022-01-27T19:26:39.924994Z",
     "shell.execute_reply.started": "2022-01-27T19:26:36.847726Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = train_df[\"meter\"] == 0\n",
    "train_df_0 = train_df[mask]\n",
    "\n",
    "mask = train_df[\"meter\"] == 1\n",
    "train_df_1 = train_df[mask]\n",
    "\n",
    "mask = train_df[\"meter\"] == 2\n",
    "train_df_2 = train_df[mask]\n",
    "\n",
    "mask = train_df[\"meter\"] == 3\n",
    "train_df_3 = train_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:39.927846Z",
     "iopub.status.busy": "2022-01-27T19:26:39.927454Z",
     "iopub.status.idle": "2022-01-27T19:26:40.587497Z",
     "shell.execute_reply": "2022-01-27T19:26:40.586676Z",
     "shell.execute_reply.started": "2022-01-27T19:26:39.927799Z"
    }
   },
   "outputs": [],
   "source": [
    "target = np.log1p(train_df_0[\"meter_reading\"])\n",
    "train = train_df_0.drop([\"building_id\", 'meter', 'meter_reading', 'timestamp','hour', \"weekend\", \"is_holiday\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:40.588866Z",
     "iopub.status.busy": "2022-01-27T19:26:40.588640Z",
     "iopub.status.idle": "2022-01-27T19:26:45.022858Z",
     "shell.execute_reply": "2022-01-27T19:26:45.022121Z",
     "shell.execute_reply.started": "2022-01-27T19:26:40.588838Z"
    }
   },
   "outputs": [],
   "source": [
    "train_1 = pd.get_dummies(train, columns = [\"site_id\", \"primary_use\",'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:26:45.024717Z",
     "iopub.status.busy": "2022-01-27T19:26:45.024166Z",
     "iopub.status.idle": "2022-01-27T19:27:19.485298Z",
     "shell.execute_reply": "2022-01-27T19:27:19.484356Z",
     "shell.execute_reply.started": "2022-01-27T19:26:45.024679Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(train_1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:27:19.489961Z",
     "iopub.status.busy": "2022-01-27T19:27:19.489656Z",
     "iopub.status.idle": "2022-01-27T19:27:21.797734Z",
     "shell.execute_reply": "2022-01-27T19:27:21.796832Z",
     "shell.execute_reply.started": "2022-01-27T19:27:19.489918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4753870674960864\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(train_1, target)\n",
    "print(r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:27:21.799280Z",
     "iopub.status.busy": "2022-01-27T19:27:21.798858Z",
     "iopub.status.idle": "2022-01-27T19:27:51.952552Z",
     "shell.execute_reply": "2022-01-27T19:27:51.951681Z",
     "shell.execute_reply.started": "2022-01-27T19:27:21.799245Z"
    }
   },
   "outputs": [],
   "source": [
    "#data import\n",
    "path = \"E:/pasca/Documents/Test/\"\n",
    "test_df = pd.read_csv(path + 'test.csv')\n",
    "building_test_df = pd.read_csv(path + 'building_metadata.csv')\n",
    "weather_test_df = pd.read_csv(path + 'weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:27:51.954041Z",
     "iopub.status.busy": "2022-01-27T19:27:51.953785Z",
     "iopub.status.idle": "2022-01-27T19:29:06.949263Z",
     "shell.execute_reply": "2022-01-27T19:29:06.947951Z",
     "shell.execute_reply.started": "2022-01-27T19:27:51.954006Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_test_df = fill_weather_dataset(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:29:07.716707Z",
     "iopub.status.busy": "2022-01-27T19:29:07.716480Z",
     "iopub.status.idle": "2022-01-27T19:29:12.826247Z",
     "shell.execute_reply": "2022-01-27T19:29:12.825473Z",
     "shell.execute_reply.started": "2022-01-27T19:29:07.716677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1272.51 MB\n",
      "Memory usage after optimization is: 358.53 MB\n",
      "Decreased by 71.8%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.9%\n",
      "Memory usage of dataframe is 21.39 MB\n",
      "Memory usage after optimization is: 5.45 MB\n",
      "Decreased by 74.5%\n"
     ]
    }
   ],
   "source": [
    "test_df = reduce_mem_usage(test_df,use_float16=True)\n",
    "building_test_df = reduce_mem_usage(building_test_df,use_float16=True)\n",
    "weather_test_df = reduce_mem_usage(weather_test_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:29:12.871339Z",
     "iopub.status.busy": "2022-01-27T19:29:12.870702Z",
     "iopub.status.idle": "2022-01-27T19:29:27.405298Z",
     "shell.execute_reply": "2022-01-27T19:29:27.404317Z",
     "shell.execute_reply.started": "2022-01-27T19:29:12.871305Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = test_df.merge(building_test_df, left_on='building_id',right_on='building_id',how='left')\n",
    "test_df = test_df.merge(weather_test_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:29:27.429880Z",
     "iopub.status.busy": "2022-01-27T19:29:27.429587Z",
     "iopub.status.idle": "2022-01-27T19:29:58.820260Z",
     "shell.execute_reply": "2022-01-27T19:29:58.819344Z",
     "shell.execute_reply.started": "2022-01-27T19:29:27.429839Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = features_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:30:23.625978Z",
     "iopub.status.busy": "2022-01-27T19:30:23.625786Z",
     "iopub.status.idle": "2022-01-27T19:30:23.635535Z",
     "shell.execute_reply": "2022-01-27T19:30:23.635018Z",
     "shell.execute_reply.started": "2022-01-27T19:30:23.625954Z"
    }
   },
   "outputs": [],
   "source": [
    "del test_df[\"year_built\"]\n",
    "del test_df[\"floor_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:30:23.637100Z",
     "iopub.status.busy": "2022-01-27T19:30:23.636505Z",
     "iopub.status.idle": "2022-01-27T19:30:29.622765Z",
     "shell.execute_reply": "2022-01-27T19:30:29.621949Z",
     "shell.execute_reply.started": "2022-01-27T19:30:23.637055Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = test_df[\"meter\"] == 0\n",
    "test_df_0 = test_df[mask]\n",
    "\n",
    "mask = test_df[\"meter\"] == 1\n",
    "test_df_1 = test_df[mask]\n",
    "\n",
    "mask = test_df[\"meter\"] == 2\n",
    "test_df_2 = test_df[mask]\n",
    "\n",
    "mask = test_df[\"meter\"] == 3\n",
    "test_df_3 = test_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = test_df_0[\"row_id\"]\n",
    "#test = test_df_0.drop(\"row_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:30:29.623973Z",
     "iopub.status.busy": "2022-01-27T19:30:29.623773Z",
     "iopub.status.idle": "2022-01-27T19:30:30.444852Z",
     "shell.execute_reply": "2022-01-27T19:30:30.444060Z",
     "shell.execute_reply.started": "2022-01-27T19:30:29.623948Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test_df_0.drop([\"row_id\",\"building_id\", 'meter', 'timestamp','hour', \"weekend\", \"is_holiday\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns = [\"site_id\", \"primary_use\",'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24755760\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T19:34:30.841418Z",
     "iopub.status.busy": "2022-01-27T19:34:30.841130Z"
    }
   },
   "outputs": [],
   "source": [
    "results = np.expm1(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.03427607  1.62069044  3.60936171 ... 12.40352071 21.10199056\n",
      " 71.29874242]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"submission_lr_new_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

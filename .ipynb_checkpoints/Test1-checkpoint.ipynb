{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebdb7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, gc, warnings\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "# init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.offline as offline\n",
    "# offline.init_notebook_mode()\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import sklearn\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9dcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/pasca/Documents/Test/building_metadata.csv\n",
      "E:/pasca/Documents/Test/sample_submission.csv\n",
      "E:/pasca/Documents/Test/test.csv\n",
      "E:/pasca/Documents/Test/train.csv\n",
      "E:/pasca/Documents/Test/weather_test.csv\n",
      "E:/pasca/Documents/Test/weather_train.csv\n"
     ]
    }
   ],
   "source": [
    "path = 'E:/pasca/Documents/Test/'\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c887fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unimportant features (see importance below)\n",
    "unimportant_cols = ['wind_direction', 'wind_speed', 'sea_level_pressure']\n",
    "target = 'meter_reading'\n",
    "\n",
    "def load_data(source='train', path=path):\n",
    "    ''' load and merge all tables '''\n",
    "    assert source in ['train', 'test']\n",
    "    \n",
    "    building = pd.read_csv(f'{path}/building_metadata.csv', dtype={'building_id':np.uint16, 'site_id':np.uint8})\n",
    "    weather  = pd.read_csv(f'{path}/weather_{source}.csv', parse_dates=['timestamp'],\n",
    "                                                           dtype={'site_id':np.uint8, 'air_temperature':np.float16,\n",
    "                                                                  'cloud_coverage':np.float16, 'dew_temperature':np.float16,\n",
    "                                                                  'precip_depth_1_hr':np.float16},\n",
    "                                                           usecols=lambda c: c not in unimportant_cols)\n",
    "    df = pd.read_csv(f'{path}/{source}.csv', dtype={'building_id':np.uint16, 'meter':np.uint8}, parse_dates=['timestamp'])\n",
    "    df = df.merge(building, on='building_id', how='left')\n",
    "    df = df.merge(weather, on=['site_id', 'timestamp'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = load_data('train')\n",
    "train.sample(7)\n",
    "\n",
    "\n",
    "groups = train.groupby('primary_use')['primary_use'].count()\n",
    "groups.plot.bar(color='xkcd:lightish blue',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_statistics(df):\n",
    "    #show missing values\n",
    "    statitics = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "    statitics.columns=['COLUMN NAME',\"MISSING VALUES\"]\n",
    "    statitics['TOTAL ROWS'] = df.shape[0]\n",
    "    statitics['% MISSING'] = round((statitics['MISSING VALUES']/statitics['TOTAL ROWS'])*100,2)\n",
    "    return statitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b414d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_statistics(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train[\"meter\"] == 0\n",
    "train_2 = train[mask]\n",
    "train_2.drop([\"meter\", \"primary_use\", \"timestamp\", \"site_id\", \"square_feet\", \"year_built\", \"floor_count\", \"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"], axis = 1, inplace = True)\n",
    "test = train_2.groupby(\"building_id\").sum()\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.scatterplot(data = train_2, x = \"building_id\", y = \"meter_reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_arr = train[\"meter\"].unique()\n",
    "for meter in meter_arr:\n",
    "    mask = train[\"meter\"] == meter\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.scatterplot(data = train[mask], x = \"building_id\", y = \"meter_reading\")\n",
    "    plt.ylabel(\"Meter: {}\".format(meter))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c83d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train[\"meter\"] == 0\n",
    "train_1 = train[mask]\n",
    "train_1.drop([\"meter\", \"primary_use\", \"timestamp\", \"site_id\", \"square_feet\", \"year_built\", \"floor_count\", \"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"], axis = 1, inplace = True)\n",
    "test = train_1.groupby(\"building_id\").sum()\n",
    "test.plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd55c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train[\"meter\"] == 0\n",
    "train_2 = train[mask]\n",
    "train_2.drop([\"meter\", \"primary_use\", \"timestamp\", \"site_id\", \"square_feet\", \"year_built\", \"floor_count\", \"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"], axis = 1, inplace = True)\n",
    "train_3 = train_2.groupby(\"building_id\").agg([np.sum])\n",
    "print(train_3.sample(5))\n",
    "#train_4 = train_3['meter_reading'].agg([np.sum])\n",
    "#train_3.plot(kind='bar' ,x='building_id',y='sum',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train.groupby('meter')['meter'].count()\n",
    "groups.plot.bar(color='xkcd:lightish blue',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_arr = train[\"meter\"].unique()\n",
    "for meter in meter_arr:\n",
    "    mask = train[\"meter\"] == meter\n",
    "    mask = train[\"building_id\"] == 1099\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.scatterplot(data = train[mask], x = \"building_id\", y = \"meter_reading\")\n",
    "    plt.ylabel(\"Meter: {}\".format(meter))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ba2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = load_data('test')\n",
    "test.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ea53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training from {train.timestamp.min()} to {train.timestamp.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a601aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7101159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_1 = train[\"meter\"] == 0\n",
    "mask = train[\"meter\"] == 0\n",
    "train_1 = train[mask]\n",
    "train_1.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_123 = plt.bar(train_1, x = \"building_id\"],y = \"meter_reading\")\n",
    "test_123.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c235ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train[\"meter\"] == 0\n",
    "train_123 = train_test.groupby('building_id')['meter_reading'].sum()\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.scatterplot(data = train_test, x = \"meter_reading\", y = train_123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_arr = train[\"meter\"].unique()\n",
    "for meter in meter_arr:\n",
    "    mask = train[\"meter\"] == meter\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.scatterplot(data = train[mask], x = \"meter_reading\", y = \"air_temperature\")\n",
    "    plt.xlabel(\"Meter: {}\".format(meter))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d37803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = train[\"meter\"] == 0\n",
    "mask2 = train[\"meter_reading\"] > 40000\n",
    "mask = np.logical_and(mask1, mask2)\n",
    "print(train.shape)\n",
    "train[mask][\"meter_reading\"] = np.mean(train[mask1][\"meter_reading\"])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = train[\"meter\"] == 3\n",
    "mask2 = train[\"meter_reading\"] > 140000\n",
    "mask = np.logical_and(mask1, mask2)\n",
    "print(train.shape)\n",
    "train[mask][\"meter_reading\"] = np.mean(train[mask1][\"meter_reading\"])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train[\"building_id\"] == 778\n",
    "train[mask][\"meter_reading\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train[\"building_id\"] == 1088\n",
    "train[mask][\"meter_reading\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for our train and valudation dataset    return df\n",
    "def correct_error_meter0_model_use(df):\n",
    "    out = df\n",
    "    new_values = out[\"meter_reading\"] * 0.2931\n",
    "    out.loc[out.meter == 0, \"meter_reading\"] = new_values\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = correct_error_meter0_model_use(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target's log-log histogram:\n",
    "ax = train.meter_reading.hist()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# describe raw values first\n",
    "train.meter_reading.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution in the types of meters\n",
    "meters = train.groupby('building_id').meter.nunique()\n",
    "plt.title('Distribution of types of meters\\n{0:electricity, 1:water, 2:steam, 3:hotwater}') # from the official starter kernel\n",
    "_ = meters.hist()\n",
    "# from the graphs it looks like steam and hotwater are reversed (e.g.: 3:steam, 2:hotwater) but that shouldn't make any difference to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_id = 1258  # a building with all 4 meters\n",
    "meters = train[train['building_id'] == building_id].meter.nunique()\n",
    "\n",
    "for meter in range(meters):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(f'Building {building_id} Meter {meter}')\n",
    "    ax2 = ax.twinx()\n",
    "    # plot meter_reading\n",
    "    idx = (train['building_id'] == building_id) & (train['meter'] == meter)\n",
    "    dates = matplotlib.dates.date2num(train.loc[idx, 'timestamp'])\n",
    "    ax2.plot_date(dates, train.loc[idx, 'meter_reading'], '-', label='meter_reading', alpha=0.8)\n",
    "    # plot air_temperature\n",
    "    dates = matplotlib.dates.date2num(train.loc[train['building_id'] == building_id, 'timestamp'])\n",
    "    ax.plot_date(dates, train.loc[train['building_id'] == building_id, 'air_temperature'], '.', color='tab:cyan', label='air_temperature')\n",
    "    ax.set_ylabel('air_temperature'); ax2.set_ylabel('meter_reading')\n",
    "    ax.legend(loc='upper left'); ax2.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "meter = 1 # pick a meter\n",
    "\n",
    "train_sample = train[(train['building_id'] == building_id) & (train['meter'] == meter)]  # same train sample as above\n",
    "\n",
    "test['meter_reading'] = 0.0\n",
    "test_sample = test[(test['building_id'] == building_id) & (test['meter'] == meter)]  # and the same meter in the test set\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "plt.title(f'Meter {meter}')\n",
    "ax.xaxis.set_tick_params(rotation=30, labelsize=10)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# plot training sample\n",
    "dates = matplotlib.dates.date2num(train_sample['timestamp'])\n",
    "ax2.plot_date(dates, train_sample['meter_reading'], '-', label='train', alpha=0.8)\n",
    "ax.plot_date(dates, train_sample['air_temperature'], '.', color='tab:cyan', label='air_temperature_train')\n",
    "\n",
    "# plot test sample\n",
    "dates = matplotlib.dates.date2num(test_sample['timestamp'])\n",
    "ax2.plot_date(dates, test_sample['meter_reading'], '*', label='test', alpha=0.8)\n",
    "ax.plot_date(dates, test_sample['air_temperature'], '.', color='tab:cyan', label='air_temperature_test')\n",
    "\n",
    "ax.set_ylabel('air_temperature'); ax2.set_ylabel('meter_reading')\n",
    "ax.legend(loc='upper left'); ax2.legend(loc='upper right')\n",
    "\n",
    "del train_sample; del test_sample; del dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the counts above expose the missing data (Should we drop or refill the missing data?)\n",
    "print(\"Ratio of available data (not NAN's):\")\n",
    "data_ratios = train.count()/len(train)\n",
    "data_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the same happening in the test set? Yes\n",
    "print(\"Ratio of available data (not NAN's):\")\n",
    "test.count()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASHRAE3Preprocessor(df, data_ratios):\n",
    "    avgs = df.loc[:,data_ratios < 1.0].mean()\n",
    "    pu_le = LabelEncoder() # Asign to a categorical variable numerical values.\n",
    "    pu_le.fit(df[\"primary_use\"])\n",
    "    \n",
    "    df = df.fillna(avgs) # refill NAN with averages\n",
    "    df['primary_use'] = np.uint8(pu_le.transform(df['primary_use']))  # encode labels\n",
    "\n",
    "    # expand datetime into its components\n",
    "    df['hour'] = np.uint8(df['timestamp'].dt.hour)\n",
    "    df['day'] = np.uint8(df['timestamp'].dt.day)\n",
    "    df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n",
    "    df['month'] = np.uint8(df['timestamp'].dt.month)\n",
    "    df['year'] = np.uint8(df['timestamp'].dt.year-2000)\n",
    "\n",
    "    # parse and cast columns to a smaller type\n",
    "#     df.rename(columns={\"square_feet\": \"log_square_feet\"}, inplace=True)\n",
    "#     df['log_square_feet'] = np.float16(np.log(df['log_square_feet']))\n",
    "    df['year_built'] = np.uint8(df['year_built']-1900)\n",
    "    df['floor_count'] = np.uint8(df['floor_count'])\n",
    "\n",
    "    # remove redundant columns\n",
    "    for col in df.columns:\n",
    "        if col in ['timestamp', 'row_id']:\n",
    "            del df[col]\n",
    "\n",
    "    # extract target column\n",
    "    if 'meter_reading' in df.columns:\n",
    "        df['meter_reading'] = np.log1p(df['meter_reading']/ df['square_feet']).astype(np.float32) # comp metric uses log errors \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = ASHRAE3Preprocessor(train, data_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30087825",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "# use a ranked correlation to catch nonlinearities\n",
    "# plot train in all columns except year, taking 100100 random samples, checking correlation using the method 'spearman'\n",
    "corr = train_transform[[col for col in train_transform.columns if col != 'year']].sample(100100).corr(method='spearman')\n",
    "_ = sns.heatmap(corr, annot=True,\n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = meter_reading\n",
    "# force the model to use the weather data instead of dates, to avoid overfitting to the past history\n",
    "features = [col for col in train_transform.columns if col not in [target, 'year', 'month', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130275b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regressor(tr_idx, val_idx, features_arr, target_str):\n",
    "    # train\n",
    "    tr_x, tr_y = train_transform[features_arr].iloc[tr_idx], train_transform[target_str][tr_idx]\n",
    "    # evaluating (\"test\")\n",
    "    vl_x, vl_y = train_transform[features_arr].iloc[val_idx], train_transform[target_str][val_idx]\n",
    "    print({'train_transform size':len(tr_x), 'eval size':len(vl_x)})\n",
    "\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "    clf = lgb.LGBMRegressor(n_estimators=6000,\n",
    "                            learning_rate=0.28,\n",
    "                            feature_fraction=0.9,\n",
    "                            subsample=0.2,  # batches of 20% of the data\n",
    "                            subsample_freq=1,\n",
    "                            num_leaves=20,\n",
    "                            metric='rmse')\n",
    "    # Metric: Root Mean Square Error (RMSE), it tells you how concentrated the data is around the line of best fit.\n",
    "    clf.fit(tr_x, tr_y,\n",
    "            eval_set=[(vl_x, vl_y)],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=200)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 4\n",
    "seed = 42\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed) # Provides train/test indices to split data in train/test sets.\n",
    "# oof_pred = np.zeros(train_transform.shape[0])  # out of fold predictions\n",
    "models = []\n",
    "\n",
    "## generating 4 train/test pair of index_arrays, and analizing wich give the better results.\n",
    "for tr_idx, val_idx in tqdm(kf.split(train_transform, train_transform['building_id']), total=folds): # train/test indices\n",
    "    clf = fit_regressor(tr_idx, val_idx, features, target)\n",
    "    models.append(clf)\n",
    "\n",
    "gc.collect() # trigger a manual garbage collection process, cleans up a huge amount of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d37739",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lgb.plot_importance(models[1], importance_type='gain', figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean feature importance, so that we can update 'unimportant_cols' above\n",
    "feature_importance = np.mean([m._Booster.feature_importance(importance_type='gain') for m in models], axis=0)\n",
    "sorted(zip(feature_importance, train_transform.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29386be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_transform.columns if col not in [target, 'year', 'month', 'day']]\n",
    "tr_idx = np.random.randint(0, 1552000, 1000000)\n",
    "tr_x, tr_y = train_transform[features].iloc[tr_idx], train_transform[target][tr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"real\": tr_y, \"prediction\": models[1].predict(tr_x)}\n",
    "p_df = pd.DataFrame(data = dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = p_df[\"real\"].values\n",
    "predicted = p_df[\"prediction\"].values\n",
    "mse = sklearn.metrics.mean_squared_error(actual, predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the counts above expose the missing data (Should we drop or refill the missing data?)\n",
    "print(\"Ratio of available data (not NAN's):\")\n",
    "data_ratios = test.count()/len(test)\n",
    "data_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75466ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and pre-process test data\n",
    "test_transform = ASHRAE3Preprocessor(test, data_ratios)\n",
    "test_transform.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a41252",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 4\n",
    "meter = 1 # pick a meter\n",
    "building_id = 1258  # a building with all 4 meters\n",
    "features = [col for col in train_transform.columns if col not in [target, 'year', 'month', 'day']]\n",
    "\n",
    "def recover_timestamp(x):\n",
    "    ''' reassemble timestamp using date components '''\n",
    "    return datetime.datetime.strptime(f'{x.year}-{x.month}-{x.day} {x.hour}', '%y-%m-%d %H')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "plt.title(f'Building {building_id} Meter {meter} on all {folds} prediction folds')\n",
    "ax.xaxis.set_tick_params(rotation=30, labelsize=10)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "train_sample = train_transform[(train_transform['building_id'] == building_id) & (train_transform['meter'] == meter)]  # same training sample as before\n",
    "test_sample = test_transform[(test_transform['building_id'] == building_id) & (test_transform['meter'] == meter)]   # and the same meter in the test set\n",
    "\n",
    "# plot training sample\n",
    "dates = matplotlib.dates.date2num(train_sample[['year', 'month', 'day', 'hour']].apply(recover_timestamp, axis=1))\n",
    "ax2.plot_date(dates, train_sample['meter_reading'], '-', label='train', alpha=0.8)\n",
    "ax.plot_date(dates, train_sample['air_temperature'], '.', color='tab:cyan', label='air_temperature_train')\n",
    "\n",
    "\n",
    "# plot prediction sample\n",
    "dates = matplotlib.dates.date2num(test_sample[['year', 'month', 'day', 'hour']].apply(recover_timestamp, axis=1))\n",
    "ax.plot_date(dates, test_sample['air_temperature'], '.', color='tab:cyan', label='air_temperature')\n",
    "for i,model in enumerate(models):\n",
    "    ax2.plot_date(dates, np.expm1(model.predict(test_sample[features])), '-', label=f'prediction{i}', alpha=0.4)\n",
    "\n",
    "ax.set_ylabel('air_temperature'); ax2.set_ylabel('meter_reading (+prediction)')\n",
    "ax.legend(loc='upper left'); ax2.legend(loc='upper right')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d342d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58130554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5080c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1db5a3c",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd81e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, gc, warnings\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "\n",
    "#import lightgbm as lgb\n",
    "\n",
    "#import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d8379",
   "metadata": {},
   "source": [
    "load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859ad2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/pasca/Documents/Test/\"\n",
    "path_laptop = \"C:/Users/Pascal Appelbaum/Documents/Test/\"\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "building_df = pd.read_csv(path + 'building_metadata.csv')\n",
    "weather_df = pd.read_csv(path + 'weather_train.csv')\n",
    "test_df = pd.read_csv(path + 'test.csv')\n",
    "weather_test_df = pd.read_csv(path + 'weather_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300aab6",
   "metadata": {},
   "source": [
    "data understanding / visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f94a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info(x, y = 1):\n",
    "    #print data infonformations\n",
    "    #y=timestamp(False,True)\n",
    "    #y=[0,1]\n",
    "    print(x.info())\n",
    "    print(10*\"-----\")\n",
    "    print(x.describe())\n",
    "    print(10*\"-----\")\n",
    "    print(\"sample:\")\n",
    "    print(x.sample(5))\n",
    "    print(msno.matrix(x))\n",
    "    if y == 0:\n",
    "        print(10*\"-----\")\n",
    "        print(\"timestamp start:\" + str(x.timestamp.min()))\n",
    "        print(\"timestamp end:\" + str(x.timestamp.max()))\n",
    "    print(10*\"-----\")\n",
    "    print(\"count of missing values:\")\n",
    "    print(x.isnull().sum())\n",
    "    print(10*\"-----\")\n",
    "    print(\"percentage of missing values:\")\n",
    "    print(x.isna().sum()/len(x)*100)\n",
    "    print(10*\"-----\")\n",
    "    print(\"missing values visualized:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05894822",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_vis_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18716/3159268486.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#set type of timestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datetime64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datetime64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mweather_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweather_vis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datetime64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_vis_df' is not defined"
     ]
    }
   ],
   "source": [
    "#preperation for data visualisation\n",
    "\n",
    "#copy dataframe for visualisation\n",
    "train_vis_df = train_df\n",
    "weather_vis_df = weather_df\n",
    "\n",
    "#set type of timestamp\n",
    "train_vis_df[\"timestamp\"] = train_vis_df[\"timestamp\"].astype(\"datetime64\")\n",
    "test_vis_df[\"timestamp\"] = test_vis_df[\"timestamp\"].astype(\"datetime64\")\n",
    "weather_vis_df[\"timestamp\"] = weather_vis_df[\"timestamp\"].astype(\"datetime64\")\n",
    "\n",
    "#merge train_df & building_df\n",
    "merge_vis_df = train_vis_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "merge_vis_df = merge_vis_df.merge(weather_vis_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ef498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df\n",
    "data_info(train_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5fa703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_df\n",
    "data_info(test_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac431bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#building_df\n",
    "data_info(building_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f270f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#weather_df\n",
    "data_info(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_test_df\n",
    "data_info(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c800e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable meter_reading is skewed\n",
    "sns.distplot(train_df.meter_reading, hist=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20634a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable meter_reading after log transformation\n",
    "sns.distplot(np.log1p(train_df.meter_reading))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of meter_readings per meter\n",
    "train_df.meter.value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26298f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#energy consumption per meter\n",
    "train_df.groupby(\"meter\").meter_reading.sum().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meter_readings per building\n",
    "train_vis_df.plot(\"building_id\", \"meter_reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buildings with the most energy consumtion\n",
    "train_df.groupby(\"building_id\").meter_reading.sum().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659cb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualisation of buildings with most energy consumtion\n",
    "for x in [1099, 778, 1168, 1197, 1159]:\n",
    "    one_building_df = train_df[train_df.building_id == x]\n",
    "    one_building_df.set_index(\"timestamp\", inplace=True)\n",
    "    one_building_df.resample(\"D\").meter_reading.sum().plot()\n",
    "    plt.title(f\"meter readings building {x}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero values in the beginning of the year at site 0\n",
    "train_vis_df[train_vis_df[\"site_id\"] == 0].plot(\"timestamp\", \"meter_reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show correlations of features\n",
    "corrmat=merge_vis_df.corr()\n",
    "fig,ax=plt.subplots(figsize=(22,20))\n",
    "sns.heatmap(corrmat,annot=True,annot_kws={'size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921dc76f",
   "metadata": {},
   "source": [
    "data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b594fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/aitude/ashrae-missing-weather-data-handling by @aitude\n",
    "\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42311d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and train weather_df fill missing values with mean\n",
    "#add day, week, month\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "weather_test_df = fill_weather_dataset(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce memory usage of all data frames\n",
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)\n",
    "test_df = reduce_mem_usage(test_df,use_float16=True)\n",
    "building_test_df = building_df\n",
    "weather_test_df = reduce_mem_usage(weather_test_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set type of timestamp\n",
    "train_df[\"timestamp\"] = train_df[\"timestamp\"].astype(\"datetime64\")\n",
    "test_df[\"timestamp\"] = test_df[\"timestamp\"].astype(\"datetime64\")\n",
    "weather_df[\"timestamp\"] = weather_df[\"timestamp\"].astype(\"datetime64\")\n",
    "weather_test_df[\"timestamp\"] = weather_test_df[\"timestamp\"].astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd398d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data frames\n",
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "\n",
    "test_df = test_df.merge(building_test_df, left_on='building_id',right_on='building_id',how='left')\n",
    "test_df = test_df.merge(weather_test_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b998af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop outlier buildings\n",
    "train_df.drop(train_df.loc[train_df['building_id']== 1099].index, inplace=True)\n",
    "train_df.drop(train_df.loc[train_df['building_id']== 778].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with to much missing values\n",
    "del train_df[\"year_built\"]\n",
    "del train_df[\"floor_count\"]\n",
    "\n",
    "del test_df[\"year_built\"]\n",
    "del test_df[\"floor_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef05371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop colums with much correlation to others\n",
    "del train_df[\"wind_direction\"]\n",
    "del train_df[\"dew_temperature\"]\n",
    "\n",
    "del test_df[\"wind_direction\"]\n",
    "del test_df[\"dew_temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save row_ids\n",
    "row_ids = test_df[\"row_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zero values in meter 0\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd94af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transformation of the target variable\n",
    "target = np.log1p(train_df[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2479d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "train = train_df.drop([\"building_id\", 'meter_reading', 'timestamp'], axis = 1)\n",
    "test = test_df.drop([\"row_id\",\"building_id\", 'timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variable\n",
    "train = pd.get_dummies(train, columns = ['meter', \"site_id\", \"primary_use\",'month'])\n",
    "test = pd.get_dummies(test, columns = ['meter', \"site_id\", \"primary_use\",'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2911dd",
   "metadata": {},
   "source": [
    "modeling linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit linear regression model\n",
    "model_lr = LinearRegression().fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show coefficients\n",
    "c_df = pd.DataFrame(data = model_lr.coef_, index = train.columns, columns = ['Coefficients'])\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38420476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise coefficients\n",
    "c_df.sort_values(by = [\"Coefficients\"])\n",
    "c_df.Coefficients.plot(kind='barh', figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test data\n",
    "results_lr = np.expm1(model_lr.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1dffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in dataframe\n",
    "results_lr_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": results_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca75c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as csv\n",
    "results_lr_df.to_csv(\"submission_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d1017",
   "metadata": {},
   "source": [
    "modeling decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c432791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit decision tree\n",
    "model_dt = DecisionTreeRegressor(random_state = 42).fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show feature importances\n",
    "fi_df = pd.DataFrame(data = model_dt.feature_importances_, index = train.columns, columns = ['Coefficients'])\n",
    "fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise feature importances\n",
    "fi_df.sort_values(by = [\"Coefficients\"])\n",
    "fi_df.Coefficients.plot(kind='barh', figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(model_dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa70e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test data\n",
    "results_dt = np.expm1(model_dt.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in dataframe\n",
    "results_dt_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": results_dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as csv\n",
    "results_dt_df.to_csv(\"submission_dt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879a2bf",
   "metadata": {},
   "source": [
    "modeling random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997796d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit random forest\n",
    "model_fr = RandomForestRegressor(n_estimators = 5).fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e395ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test data\n",
    "results_fr = np.expm1(model_fr.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d941451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in dataframe\n",
    "results_fr_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": results_fr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fb5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as csv\n",
    "results_fr_df.to_csv(\"submission_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165df45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
